# big-data-course

## Setup

- run spark cluster:
    `docker-compose up -d`

- run task app:
    `./task.sh`

- delete/stop:
    `docker-compose down && docker-compose rm`


## Results:

- results are @ `./app/data/results/`

--- 

#### Example

- 1 task:

    ![](/res/res1.png)

- 2 task:

    ![](/res/res2.png)

- 4 task:

    ![](/res/res4.png)

- 5 task:

    ![](/res/res5.png)

- 6 task:

    ![](/res/res6.png)
